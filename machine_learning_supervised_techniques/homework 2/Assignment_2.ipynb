{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 2: Gaussian Classifier, Bias-Variance Decomposition, Evaluation Measures </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material, no matter whether in printed or electronic form,\n",
    "may be used for personal and non-commercial educational use\n",
    "only. Any reproduction of this material, no matter whether as a\n",
    "whole or in parts, no matter whether in printed or in electronic\n",
    "form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Automatic Testing Guidelines</h2>\n",
    "\n",
    "Automatic unittesting requires you, as a student, to submit a notebook which contains strictly defined objects.\n",
    "Strictness of definition consists of unified shapes, dtypes, variable names, and more.\n",
    "\n",
    "Within the notebook, we provide detailed instructions which you should follow in order to maximize your final grade. Please keep in mind:\n",
    "\n",
    "* Don't add any cells but use the ones provided by us. You may notice that most cells are tagged such that the unittest routine can recognise them.\n",
    "\n",
    "* We highly recommend you to develop your code within the provided cells. You can implement helper functions where needed unless you put them in the same cell they are actually called. Always make sure that implemented functions have the correct output and given variables contain the correct data type. Don't import any other packages than listed in the cell with the \"imports\" tag.\n",
    "\n",
    "* Never use variables you defined in another cell in your functions directly; always pass them to the function as a parameter. In the unittest they won't be available either.\n",
    "\n",
    "*Good luck! :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 1: Gaussian classifier: visualization & parameter estimation (10 points)</h2>\n",
    "\n",
    "The goal of this task is to explore the given (artificial) data before diving into the classification function. To do this, we will use `matplotlib` to plot the data set and `numpy` to estimate the means & covariance matrices of the classes as well as the probability of encountering a positive/negative example.\n",
    "\n",
    "* **Task 1.1**: Visualize the data stored in `normal.csv` with two different colors using a scatter plot and store it in the given variable. Always label the axes of all your plots.\n",
    "* **Task 1.2**: We assume that the data is distributed according to a two-dimensional multivariate normal distribution:\n",
    "    - Write a function that estimates the means and covariance matrices of each class as well as the distributions $p(y=+1)$ and $p(y=-1)$\n",
    "    - Return a tuple containing the results (the resulting list should be of length 6). The datatype for `covXpos`, `covXneg`, `meanXpos` and `meanXneg` should be a numpy array, for $p(y=+1)$ and $p(y=-1)$ it should be float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">1.1. Code & question (4 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "Plot1"
    ]
   },
   "outputs": [],
   "source": [
    "# read data, split into X (features) and y (labels)\n",
    "Z = np.genfromtxt('normal.csv', delimiter=',')\n",
    "X, y = Z[:,:-1], Z[:,-1]\n",
    "\n",
    "# your code for the visualization\n",
    "\n",
    "# example: plt.figure...\n",
    "# plt.plot..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer the following yes/no questions concerning the distribution of the data:***\n",
    "\n",
    "a_) Would a linear regression method be reasonable for this task?<br>\n",
    "b_) Would a linear classifier roughly achieve a better performance than 33% misclassification?<br>\n",
    "\n",
    "To answer the question, assign \"True\" or \"False\" boolean values to variables in the next cell. A non-correctly answered question yields negative points and no answer (i.e. answer “None”) gives 0 points for a question. More details on grading can be found in the [FAQ sheet](https://docs.google.com/document/d/11ccAoEWh1APAoj79kGFiL64_7OL7RApPUHJ2-cvS2s0/edit?usp=sharing).<br>\n",
    "<b>Note:</b> Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Q0"
    ]
   },
   "outputs": [],
   "source": [
    "# examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "# your answers go here ↓↓↓\n",
    "a_=None\n",
    "b_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">1.2. Code (6 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "est_mean_cov"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that estimates the means and covariance matrices from the given data as well as the probability to encounter\n",
    "a positive/negative example respectively\n",
    "@param X_, np ndarray, data matrix\n",
    "@param y_, np ndarray, data vector\n",
    "\"\"\"\n",
    "def est_mean_cov(X_,y_):\n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "covXpos, meanXpos, p_ypos, covXneg, meanXneg, p_yneg = est_mean_cov(X,y)\n",
    "    \n",
    "# print corresponding values\n",
    "print(\"Positive class (blue):\\n\")\n",
    "print(\"Covariance:\")\n",
    "print(pd.DataFrame(covXpos,columns=[\"x1\",\"x2\"],index=[\"x1\",\"x2\"]),\"\\n\")\n",
    "print(\"Mean = \", meanXpos, \"\\n\")\n",
    "print(\"p(y=+1) =\", p_ypos, \"\\n\\n\")\n",
    "print(\"Negative class (orange):\\n\")\n",
    "print(\"Covariance:\")\n",
    "print(pd.DataFrame(covXneg,columns=[\"x1\",\"x2\"],index=[\"x1\",\"x2\"]),\"\\n\")\n",
    "print(\"Mean =\", meanXneg, \"\\n\")\n",
    "print(\"p(y=-1) =\", p_yneg, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 2: Gaussian classifier: compute classifier & visualization (20 points)</h2>\n",
    "\n",
    "Now that we (hopefully) get a good idea of the data, we want to implement a classifier and show its effects using a plot.\n",
    "\n",
    "- **Task 2.1**: Compute an optimal classification function $g$ in `calc_func_g()` (see slide \"Explicit example: Gaussian classifier: Part 2\" from lecture Unit2.pdf). To do this, you should:\n",
    "    - Calculate the values of the corresponding parameters $\\mathbf{A}$, $\\mathbf{b}$ and $c$ in the provided functions.\n",
    "    - Store the results in the given parameters **par_A** (np.array), **par_b** (np.array), **par_c** (float), and **func_g** (np.array).\n",
    "    - Print the values of $\\mathbf{A}$, $\\mathbf{b}$ and $c$ that you have calculated with their respective shapes.\n",
    "    - Note: You can reuse the results from the previous exercise here.\n",
    "\n",
    "* **Task 2.2**: Visualize the classification function and the decision boundaries including the original points from Task 1.1. in **one** two-dimensional plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">2.1 Code (10 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters1"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These functions should contain the calculations for the respective parameters and return the result.\n",
    "@param covXpos, np ndarray, covariance matrix of positive examples\n",
    "@param meanXpos, np ndarray, mean of positive examples\n",
    "@param covXneg, np ndarray, covariance matrix of negativ examples\n",
    "@param meanXneg, np ndarray, mean of negative examples\n",
    "@param p_ypos, float, probability of encountering a positive example\n",
    "@param p_yneg, float, probability of encountering a negative example\n",
    "Hint: You may want to check out np.linalg.inv\n",
    "\"\"\"\n",
    "def calc_par_A(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "def calc_par_b(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "def calc_par_c(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "\"\"\"\n",
    "Combine the previously calculated parameters to the optimal classification function g.\n",
    "@param points, np.array, the points that the function g should be applied to\n",
    "\"\"\"\n",
    "def calc_func_g(par_A, par_b, par_c, points):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "# some code that should help you\n",
    "X1, X2 = np.mgrid[-10.5:10.5:500j, -10.5:10.5:500j]\n",
    "points = np.c_[X1.ravel(), X2.ravel()]\n",
    "    \n",
    "par_A = calc_par_A(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg)\n",
    "par_b = calc_par_b(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg)\n",
    "par_c = calc_par_c(covXpos, meanXpos, covXneg, meanXneg, p_ypos, p_yneg)\n",
    "func_g = calc_func_g(par_A, par_b, par_c, points)\n",
    "\n",
    "# print the values shapes of par_A, par_b, and par_c here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">2.2 Code & question (10 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters2"
    ]
   },
   "outputs": [],
   "source": [
    "# your code for the visualization\n",
    "\n",
    "# example: plt.figure...\n",
    "# plt.plot..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer the following questions about the plot you just created:***\n",
    "\n",
    "c_) Did the classifier perform well on the task i.e. do the decision boundaries seem to match the classes as plotted in Task 1.1?<br>\n",
    "d_) Are datapoints that lie in the middle, overlapping region of the two classes more prone to being misclassified?<br>\n",
    "\n",
    "To answer the question, assign \"True\" or \"False\" boolean values to variables in the next cell. A non-correctly answered question yields negative points and no answer (i.e. answer “None”) gives 0 points for a question. More details on grading can be found in the [FAQ sheet](https://docs.google.com/document/d/11ccAoEWh1APAoj79kGFiL64_7OL7RApPUHJ2-cvS2s0/edit?usp=sharing).<br>\n",
    "<b>Note:</b> Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers go here ↓↓↓\n",
    "c_=None\n",
    "d_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 3: Details for bias-variance decomposition for quadratic loss (15 points)</h2>\n",
    "\n",
    "An explicit formula of the bias variance decomposition for the quadratic loss was mentioned in the lecture. In this task, you will be asked to fill in some details that haven't been discussed there. To this end, let us introduce some notation:\n",
    "\n",
    "$Z_l$ denotes a data matrix of $l$ elements from our data set $Z =(X,\\mathbf{y})$ with $X$ the feature matrix and $\\mathbf{y}$ the label vector. $g(\\mathbf{x}_0;\\mathbf{w}(Z_l)))$ denotes the model, with a parameter vector $\\mathbf{w}(Z_l)$ originating from $Z_l$, and $y$ is the label corresponding to a feature vector $\\mathbf{x}_0$. \n",
    "\n",
    "Our object of interest is the expected prediction error (EPE) for\n",
    "$\\mathbf{x}_0\\in X$ in case of the quadratic loss, i.e.:\n",
    "\n",
    "$$\\mathrm{EPE}(\\mathbf{x}_0) = \\mathrm{E}_{y\\mid\n",
    "\\mathbf{x}_0,Z_l}\\big(L_{\\mathbf{q}}(y,g(\\mathbf{x}_0;\\mathbf{w}(Z_l)))\\big)\n",
    "= \\mathrm{E}_{y\\mid\n",
    "\\mathbf{x}_0,Z_l}\\big((y-g(\\mathbf{x}_0;\\mathbf{w}(Z_l)))^2\\big)$$\n",
    "\n",
    "We assume that $y\\!\\mid\\!\\mathbf{x}_0$ and the selection of training samples $Z_l$ are\n",
    "independent which results in the following reformulation of the total expected prediction error:\n",
    "\n",
    "$$\\mathrm{EPE}(\\mathbf{x}_0) = \\mathrm{E}_{y\\mid\n",
    "\\mathbf{x}_0}\\Big(\\mathrm{E}_{Z_l}\\big((y-g(\\mathbf{x}_0;\\mathbf{w}(Z_l)))^2\\big)\\Big)\\quad \\text{(1)}$$\n",
    "\n",
    "Show that we can obtain the following bias-variance decomposition:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{EPE}(\\mathbf{x}_0)=&\\,\\operatorname{Var}(y\\!\\mid\\!\\mathbf{x}_0)\\\\\n",
    "&+\\Big(\\mathrm{E}_{y\\mid\\mathbf{x}_0}(y)-E_{Z_l}\\big(g(\\mathbf{x}_0;\\mathbf{w}(Z_l))\\big)\\Big)^2\\\\\n",
    "&+\\mathrm{E}_{Z_l}\\Big(\\big(g(\\mathbf{x}_0;\\mathbf{w}(Z_l))-E_{Z_l}(g(\\mathbf{x}_0;\\mathbf{w}(Z_l)))\\big)^2\\Big)\n",
    "\\end{align*}\n",
    "\n",
    "For your calculation please use the given notation. Follow the steps indicated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">3.1 Calculation (5 points): Expand the Expected Prediction Error.</h3>\n",
    "\n",
    "Expand $\\mathrm{EPE}(\\mathbf{x}_0)$, i.e. eq. (1) above, and write it as three separate terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Calculation1"
    ]
   },
   "source": [
    "Your calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">3.2 Calculation (2 points): Rewrite $\\operatorname{Var}(y\\!\\mid\\!\\mathbf{x}_0)$ using expected values. </h3>\n",
    "\n",
    "Write the model variance in terms of expectation values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Calculation2"
    ]
   },
   "source": [
    "Your calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">3.3. Calculation (3 points): Expand the squared bias.</h3>\n",
    "\n",
    "Expand the squared bias and write it in three separate terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Calculation3"
    ]
   },
   "source": [
    "Your calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">3.4 Calculation (5 points): Expand the variance of the model.</h3>\n",
    "\n",
    "Write the model variance in (first three, then simplified to two) separate terms.\n",
    "\n",
    "(Eventually, you can see that adding up 3.2., 3.3., and 3.4., some terms cancel and exactly 3.1. remains.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Calculation4"
    ]
   },
   "source": [
    "Your calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 4: Bias-variance decomposition for regression (40 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">4.1 Question (10 points):</h3>\n",
    "\n",
    "Consider the following one-dimensional regression task: inputs $x$ are\n",
    "sampled from the uniform distribution in $[−1, 3] \\subset \\mathbb{R}$ and targets $y$ are given as\n",
    "\n",
    "\\begin{align*}\n",
    "f(x) &= 0.6\\,x^4 + 2\\,x^3 - 8\\,x^2 \\\\\n",
    "y &= f(x) + \\varepsilon,\n",
    "\\end{align*}\n",
    "\n",
    "where $\\varepsilon$ is independent normally distributed noise with $\\mu=0$ and $\\sigma^2 = 0.09$. \n",
    "\n",
    "***What are $E(y\\!\\mid\\!x_0)$ and the unavoidable error $\\operatorname{Var}(y\\!\\mid\\!x_0)$ for a fixed $x_0$ in this setting?***\n",
    "\n",
    "e_)   $E(y\\!\\mid\\!x_0) = 0.6\\,\\sigma^4 + 2\\,\\sigma^3 - 8\\,\\sigma^2 \\text{    and    } \\operatorname{Var}(y\\!\\mid\\!x_0) = x_0^2$. <br>\n",
    "f_)   $E(y\\!\\mid\\!x_0) = 0.6\\,x_0^4 + 2\\,x_0^3 - 8\\,x_0^2 \\text{ and }\\operatorname{Var}(y\\!\\mid\\!x_0) = \\sigma^2$. <br>\n",
    "g_)   $E(y\\!\\mid\\!x_0) = 0.6\\,\\sigma^4 + 2\\,\\sigma^3 - 8\\,\\sigma^2 \\text{ and }  \\operatorname{Var}(y\\!\\mid\\!x_0) = \\sigma^2$. <br>\n",
    "h_)   $E(y\\!\\mid\\!x_0) = 0.6\\,x_0^4 + 2\\,x_0^3 - 8\\,x_0^2 \\text{    and    } \\operatorname{Var}(y\\!\\mid\\!x_0) = 0.6\\,x_0^4 + 2\\,x_0^3 - 8\\,x_0^2+\\sigma^2$.<br>\n",
    "\n",
    "To answer the question, assign \"True\" or \"False\" boolean values to variables in the next cell. A non-correctly answered question yields negative points and no answer (i.e. answer “None”) gives 0 points for a question. More details on grading can be found in the [FAQ sheet](https://docs.google.com/document/d/11ccAoEWh1APAoj79kGFiL64_7OL7RApPUHJ2-cvS2s0/edit?usp=sharing).<br>\n",
    "<b>Note:</b> Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "Q1"
    ]
   },
   "outputs": [],
   "source": [
    "# your answers go here ↓↓↓\n",
    "e_=None\n",
    "f_=None\n",
    "g_=None\n",
    "h_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to perform polynomial regression to illustrate the bias-variance decomposition for the regression task described before. To this end, perform the following steps:\n",
    " * **Task 4.2**:\n",
    "    * Implement the function `create_train_X` which should return $k=200$ training sets with $l=20$ samples in the form of a numpy array.\n",
    "    * Implement the function `create_train_y` according to the function described at the beginning of this task.\n",
    "    * Below, we provide the code for a function that trains a polynomial regression model with degree $m$ on a given training set and returns the prediction for a given test set. Use this to implement the function `bias_var` that estimates for each degree $m=1,...,11$ the squared bias and the variance from the predictions for each of the $k=200$ training sets at $x_0=1.8$ and stores them in the lists sqbias and variance (which are already initiated as empty lists). Each of these two lists should then only contain $11$ elements.\n",
    " * **Task 4.3**: \n",
    "   * Utilize the function `pol_reg_pred` to produce <em>one</em> plot that simultaneously visualizes the training data as dots (plot only the <em>first</em> instance of the $k$ training sets, i.e. the 20 points from the first set) and the corresponding models for $m=1,3,11$. Don't forget to label the axes. Note: Make sure to produce the plot in the correct (second) cell.\n",
    "   * Finally, visualize your results in <em>one</em> plot where the dependence of the variance and squared bias versus $m$ is shown. Again, the axes should be labeled appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">4.2 Code (15 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "poly_reg"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# some code that should help you\n",
    "# do not change the seed\n",
    "np.random.seed(14)\n",
    "\n",
    "def pol_reg_pred(X_train,y_train,X_test,m):\n",
    "    poly_reg = PolynomialFeatures(m)\n",
    "    X_poly_train = poly_reg.fit_transform(X_train.reshape(-1, 1))\n",
    "    X_poly_test= poly_reg.fit_transform(X_test.reshape(-1, 1))\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_poly_train, y_train)\n",
    "    y_pred = lin_reg.predict(X_poly_test)\n",
    "    return y_pred\n",
    "\n",
    "def f(x):\n",
    "    return 0.6 * x**4 + 2 * x**3 - 8 * x**2\n",
    "\n",
    "def create_train_X(k,l):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "    \n",
    "def create_train_y(k,l,X_train):\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "\n",
    "k = 200\n",
    "l = 20\n",
    "M = 11\n",
    "X_train = create_train_X(k,l)\n",
    "y_train = create_train_y(k,l,X_train)\n",
    "\n",
    "def bias_var(X_train,y_train): \n",
    "    x0 = np.array([1.8])\n",
    "    sqbias = []\n",
    "    variance = []\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "    \n",
    "    return (sqbias,variance)\n",
    "    \n",
    "sqbias, variance = bias_var(X_train,y_train)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(sqbias)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">4.3 Code (10 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "plots2"
    ]
   },
   "outputs": [],
   "source": [
    "# your code for the visualization (remember, you need to create two plots for this subtask)\n",
    "\n",
    "# example: plt.figure...\n",
    "# plt.plot..."
   ]
  },
  {
   "attachments": {
    "Bias_variance.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">4.4 Question (5 points):</h3>\n",
    "\n",
    "If you did the previous task correctly, the resulting plot should look like this:\n",
    "\n",
    "![Bias_variance.jpg](attachment:Bias_variance.jpg)    \n",
    "\n",
    "\n",
    "***What observations can you make from this plot? Tick the correct boxes (several may be correct):***\n",
    "\n",
    "\n",
    "i_)   The variance is lowest for models which are too simple, i.e. $m<3$. <br>\n",
    "j_) For appropriate complexity, i.e. $3 \\leq m < 7$, both model variance and bias are low, which indicates good generalization abilities.<br>\n",
    "k_)   As the model becomes too complex, i.e. $m \\geq 7$, the variance increases again while the bias still decreases. This is an indication for underfitting.<br>\n",
    "l_) For models with $m \\geq 7$, the variance is high (i.e. significantly larger than $0$) because the independent noise has zero mean and high individual biases cancel in expectation. <br>\n",
    "m_)  For models with $m \\geq 7$, the bias is still low (i.e. close to $0$) because the independent noise has zero mean and high individual biases cancel in expectation. <br>\n",
    "\n",
    "To answer the question, assign \"True\" or \"False\" boolean values to variables in the next cell. A non-correctly answered question yields negative points and no answer (i.e. answer “None”) gives 0 points for a question. More details on grading can be found in the [FAQ sheet](https://docs.google.com/document/d/11ccAoEWh1APAoj79kGFiL64_7OL7RApPUHJ2-cvS2s0/edit?usp=sharing).<br>\n",
    "<b>Note:</b> Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "Q2"
    ]
   },
   "outputs": [],
   "source": [
    "# your answers go here ↓↓↓\n",
    "i_=None\n",
    "j_=None\n",
    "k_=None\n",
    "l_=None\n",
    "m_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Task 5: Evaluation metrics for imbalanced data sets (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a classifier with discriminant function $\\bar g$.\n",
    "For a given labeled data set, the following results are obtained:\n",
    "$$\\begin{array}{|r|r|}\n",
    "\\hline\n",
    "y & \\bar g(x)\\\\\n",
    "\\hline \\hline\n",
    " +1 & 0.93 \\\\\n",
    " +1 & 0.51 \\\\\n",
    " +1 & 0.48 \\\\\n",
    " -1 & 0.13 \\\\\n",
    " +1 & 0.02 \\\\\n",
    " -1 & -0.11 \\\\\n",
    " -1 & -0.25 \\\\\n",
    " -1 & -0.37 \\\\\n",
    " +1 & -0.41 \\\\\n",
    " -1 & -1.68 \\\\\n",
    " +1 & -2.23 \\\\\n",
    "\\hline\n",
    "\\end{array}$$\n",
    "\n",
    "* **Task 5.1**: Compute the confusion matrix using the usual zero threshold.\n",
    "Complete the given function to calculate the following evaluation measures:\n",
    "ACC, TPR, TNR, FPR, FNR, PREC, and $F_1$, and store the exact results in the respective variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">5.1 Calculation (8 points):</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Reminder:</b> Confusion Matrix structure:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    " &\\bar g(x)=+1  & \\bar g(x)=-1\\\\\n",
    " \\hline\n",
    " y=+1 & \\text{TP}  & \\text{FN} \\\\\n",
    " \\hline\n",
    " y=-1 & \\text{FP} & \\text{TN} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "calculation1"
    ]
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "_TP = 0\n",
    "_TN = 0\n",
    "_FP = 0\n",
    "_FN = 0\n",
    "\n",
    "# evaluation measures\n",
    "def evaluate_measures(TP,TN,FP,FN): \n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "    \n",
    "    return (ACC,TPR,TNR,FPR,FNR,PREC,BACC,F1)\n",
    "    \n",
    "_ACC,_TPR,_TNR,_FPR,_FNR,_PREC,_BACC,_F1 = evaluate_measures(_TP,_TN,_FP,_FN)\n",
    "\n",
    "print(\"ACC: {:.3f}\\nTPR: {:.3f}\\nTNR: {:.3f}\\nFPR: {:.3f}\\nFNR: {:.3f}\\nPREC: {:.3f}\\nBACC: {:.3f}\\nF1: {:.3f}\".format(_ACC,_TPR,_TNR,_FPR,_FNR,_PREC,_BACC,_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a population of 1000 people and we know that 50 are infected with the corona virus.\n",
    "* **Task 5.2**: Assume that the population is tested with an assay that has a certain specificity and sensitivity. What is the probability that a person is *not* infected if they are diagnosed as ill by the test? Write a function that returns the desired value. Then check your calculation using specificity of $97 \\%$ and sensitivity of $98 \\%$.\n",
    "\n",
    "**Note**: Round your result to 3 decimal points, i.e. 0.987 if its 98.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">5.2 Calculation (7 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "calculation2"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function should return the desired probability. \n",
    "@param spec, float, specificity\n",
    "@param sens, float, sensitivity\n",
    "@param pop, int, population\n",
    "@param inf, int, infected\n",
    "\"\"\"\n",
    "def calc_prob(spec,sens,pop,inf):\n",
    "    population = pop\n",
    "    infected = inf\n",
    "    \n",
    "    # replace the following line with your lines of code\n",
    "    raise NotImplementedError(\"You have not implemented this function\")\n",
    "    \n",
    "_result = calc_prob(0.97,0.98,1000,50)\n",
    "print(\"The probability that a person who is tested positive is in fact not infected is {}\".format(_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable\n"
     ]
    }
   ],
   "source": [
    "# executability check\n",
    "est_mean_cov(X,y)\n",
    "calc_par_A(np.eye(2),np.ones(shape=2),np.eye(2),np.ones(shape=2),1,1)\n",
    "calc_par_b(np.eye(2),np.ones(shape=2),np.eye(2),np.ones(shape=2),1,1)\n",
    "calc_par_c(np.eye(2),np.ones(shape=2),np.eye(2),np.ones(shape=2),1,1)\n",
    "calc_func_g(np.ones(shape=(2,2)),np.ones(2),1,np.ones(shape=(250000,2)))\n",
    "create_train_X(1,1)\n",
    "create_train_y(1,1,np.ones((200,20)))\n",
    "bias_var(np.ones((200,20)),np.ones((200,20)))\n",
    "evaluate_measures(1,1,1,1)\n",
    "calc_prob(1,1,1,1)\n",
    "print(\"Executable\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
